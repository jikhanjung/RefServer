#!/usr/bin/env python3
"""
BGE-M3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
Docker ì´ë¯¸ì§€ì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ ë¡œì»¬ì— ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
"""

import os
import sys
from sentence_transformers import SentenceTransformer

def download_bge_m3_model():
    """BGE-M3 ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œ"""
    
    model_name = "BAAI/bge-m3"
    local_model_path = "./models/bge-m3-local"
    
    print(f"Downloading BGE-M3 model: {model_name}")
    print("This may take several minutes depending on your internet connection...")
    
    try:
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("./models", exist_ok=True)
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print("Loading model from HuggingFace...")
        model = SentenceTransformer(model_name)
        
        # ë¡œì»¬ì— ì €ì¥
        print(f"Saving model to {local_model_path}")
        model.save(local_model_path)
        
        print("âœ… Model download completed successfully!")
        print(f"Model saved to: {os.path.abspath(local_model_path)}")
        
        # ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(local_model_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                total_size += os.path.getsize(filepath)
        
        print(f"Total model size: {total_size / (1024*1024):.1f} MB")
        
        # ëª¨ë¸ íŒŒì¼ ëª©ë¡ ì¶œë ¥
        print("\nModel files:")
        for root, dirs, files in os.walk(local_model_path):
            level = root.replace(local_model_path, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files:
                print(f"{subindent}{file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error downloading model: {e}")
        return False

def verify_model():
    """ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ê²€ì¦"""
    local_model_path = "./models/bge-m3-local"
    
    if not os.path.exists(local_model_path):
        print("âŒ Model directory not found")
        return False
    
    try:
        print("Verifying downloaded model...")
        
        # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
        model = SentenceTransformer(local_model_path)
        
        # ê°„ë‹¨í•œ ì„ë² ë”© í…ŒìŠ¤íŠ¸
        test_text = "This is a test sentence for model verification."
        embedding = model.encode(test_text)
        
        print(f"âœ… Model verification successful!")
        print(f"Embedding dimension: {len(embedding)}")
        print(f"Test embedding shape: {embedding.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Model verification failed: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Starting BGE-M3 model download...")
    print("=" * 50)
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    success = download_bge_m3_model()
    
    if success:
        print("\n" + "=" * 50)
        print("ğŸ” Verifying downloaded model...")
        
        # ëª¨ë¸ ê²€ì¦
        verify_success = verify_model()
        
        if verify_success:
            print("\n" + "=" * 50)
            print("ğŸ‰ All done! Model is ready for Docker deployment.")
            print("\nNext steps:")
            print("1. Build Docker image with: docker-compose build")
            print("2. The model will be available at /app/models/bge-m3-local inside the container")
        else:
            print("\nâŒ Model verification failed. Please try downloading again.")
            sys.exit(1)
    else:
        print("\nâŒ Model download failed. Please check your internet connection and try again.")
        sys.exit(1)